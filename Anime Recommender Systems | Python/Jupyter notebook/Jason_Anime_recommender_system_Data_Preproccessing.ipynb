{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YUEHCHAO WU\n",
    "# Anime Recommender System\n",
    "# Data Preproccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Source-of-Data-:-Kaggle-Anime-Recommendations-Database\" data-toc-modified-id=\"Source-of-Data-:-Kaggle-Anime-Recommendations-Database-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Source of Data : <a href=\"https://www.kaggle.com/CooperUnion/anime-recommendations-database\" target=\"_blank\">Kaggle Anime Recommendations Database</a></a></span></li><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Load-Anime-&amp;-Anime_rating-csv-into-pandas-Dataframe\" data-toc-modified-id=\"Load-Anime-&amp;-Anime_rating-csv-into-pandas-Dataframe-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Anime &amp; Anime_rating csv into pandas Dataframe</a></span></li><li><span><a href=\"#Data-preproccesing\" data-toc-modified-id=\"Data-preproccesing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data preproccesing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-My-Custom-Data-Cleaning-Module\" data-toc-modified-id=\"Import-My-Custom-Data-Cleaning-Module-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import My Custom Data Cleaning Module</a></span></li><li><span><a href=\"#10-Core-Operation-&amp;-One-Scale-Rater-Elimination-on-Anime_rating-using-clean_data()\" data-toc-modified-id=\"10-Core-Operation-&amp;-One-Scale-Rater-Elimination-on-Anime_rating-using-clean_data()-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>10-Core Operation &amp; One-Scale Rater Elimination on <code>Anime_rating</code> using <code>clean_data()</code></a></span></li><li><span><a href=\"#Limit-experiment-to-Movie-Comedy-Anime\" data-toc-modified-id=\"Limit-experiment-to-Movie-Comedy-Anime-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Limit experiment to Movie Comedy Anime</a></span></li><li><span><a href=\"#Get-Final-Form-of-Anime-Rating-Datasets-ready-in-Surprise\" data-toc-modified-id=\"Get-Final-Form-of-Anime-Rating-Datasets-ready-in-Surprise-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Get Final Form of Anime Rating Datasets ready in Surprise</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Splitting-(train-,test)-using-Straitification-on-'user_id'\" data-toc-modified-id=\"Data-Splitting-(train-,test)-using-Straitification-on-'user_id'-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Data Splitting (train ,test) using Straitification on <code>'user_id'</code></a></span></li><li><span><a href=\"#Load-Final-form-of-Anime-rating--Data-(-final_form_data,-train,-test-)-into-Surprise-Object\" data-toc-modified-id=\"Load-Final-form-of-Anime-rating--Data-(-final_form_data,-train,-test-)-into-Surprise-Object-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Load Final form of Anime rating  Data ( final_form_data, train, test ) into Surprise Object</a></span></li><li><span><a href=\"#Convert-data-into-surprise-training-sets-&amp;-testing-sets-for-modeling\" data-toc-modified-id=\"Convert-data-into-surprise-training-sets-&amp;-testing-sets-for-modeling-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>Convert data into surprise training sets &amp; testing sets for modeling</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source of Data : [Kaggle Anime Recommendations Database](https://www.kaggle.com/CooperUnion/anime-recommendations-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T06:23:41.002818Z",
     "start_time": "2018-05-19T06:23:40.969271Z"
    }
   },
   "outputs": [],
   "source": [
    "#standard tools\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel,probplot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wordcloud import WordCloud\n",
    "import math\n",
    "import copy as cp\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#from surprise\n",
    "from surprise import KNNWithMeans,SVD,SVDpp,NMF,SlopeOne,CoClustering\n",
    "from surprise import Reader, Dataset,accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, ShuffleSplit, GridSearchCV\n",
    "from surprise.prediction_algorithms import PredictionImpossible\n",
    "from surprise.model_selection import train_test_split as surprisesplit\n",
    "from surprise import dump\n",
    "\n",
    "#user defined functions\n",
    "from prec_recall import precision_recall_at_k,pr_eval\n",
    "from sigweight import KNNSigWeighting\n",
    "from Rank import *\n",
    "from data_cleaning import *\n",
    "from hybrid import WeightedHybrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Anime & Anime_rating csv into pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T01:54:29.995752Z",
     "start_time": "2018-05-19T01:54:26.217287Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of anime files\n",
    "Alst=glob.glob('anime*') \n",
    "\n",
    "#load anime files into list of pandas df\n",
    "Adf=[]\n",
    "for i in Alst:\n",
    "    Adf.append(pd.read_csv(i))\n",
    "\n",
    "Anime_rating = Adf[1]\n",
    "Anime = Adf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T02:14:53.015595Z",
     "start_time": "2018-05-19T02:14:52.509381Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove obesrvations that rating = -1\n",
    "mask=Anime_rating['rating']!=-1\n",
    "Anime_rating=Anime_rating[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preproccesing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import My Custom Data Cleaning Module\n",
    "Codes: [data_cleaning.py](./data_cleaning.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T17:07:32.767380Z",
     "start_time": "2018-07-20T17:07:32.748330Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Core Operation & One-Scale Rater Elimination on `Anime_rating` using `clean_data()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T22:22:16.301292Z",
     "start_time": "2018-05-16T22:20:40.111138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Iteration 1 ##\n",
      "There are one-scale raters!\n",
      "one_Scale_rater_eliminator excuted\n",
      "\n",
      "\n",
      "There are some user or item has less than 10 ratings!\n",
      "core_operator excuted!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "## Iteration 2 ##\n",
      "No one scale Rater!\n",
      "\n",
      "\n",
      "There are some user or item has less than 10 ratings!\n",
      "core_operator excuted!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "## Iteration 3 ##\n",
      "No one scale Rater!\n",
      "\n",
      "\n",
      "No item & user has less than 10 ratinngs!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Data is cleaned!\n"
     ]
    }
   ],
   "source": [
    "#perform eliminaton & core_operation\n",
    "core=data_cleaner(Anime_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T03:36:23.970973Z",
     "start_time": "2018-05-01T03:35:50.479772Z"
    }
   },
   "outputs": [],
   "source": [
    "#write 10 core data to csv file 'core_rating.csv'\n",
    "core.to_csv('core_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T03:40:39.712633Z",
     "start_time": "2018-05-09T03:40:38.229433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary of Anime Rating Data after cleaning ## \n",
      "\n",
      "Number of observations: 6247010 \n",
      "Number of Unique users: 54743\n",
      "Number of Unique animes: 7359\n",
      "Number of Unique ratings: 10\n",
      "*rating scales: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "Density: 0.015506893510584463\n",
      "======================================================================\n",
      "\n",
      "\n",
      "## first 10 rows of Anime Rating Data after cleaning ## \n",
      "\n",
      "     user_id  anime_id  rating\n",
      "156        3        20       8\n",
      "157        3       154       6\n",
      "158        3       170       9\n",
      "159        3       199      10\n",
      "160        3       225       9\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "## print summary of  anime rating data after 10 core operation\n",
    "print('## Summary of Anime Rating Data after cleaning ## \\n')\n",
    "print('Number of observations: {} '.format(len(core)))\n",
    "\n",
    "\n",
    "for i in core.nunique().index:\n",
    "    print('Number of Unique {0}s: {1}'.format(i.split('_')[0],core.nunique()[i]))\n",
    "\n",
    "print('*rating scales: {}'.format(np.sort(core['rating'].unique())))\n",
    "\n",
    "print('Density: {}'.format(len(core)/(core.nunique()[0]*core.nunique()[1])))\n",
    "\n",
    "print('='*70)    \n",
    "print('\\n\\n## first 10 rows of Anime Rating Data after cleaning ## \\n')\n",
    "print(core.head())\n",
    "print('='*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit experiment to Movie Comedy Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T22:57:23.798789Z",
     "start_time": "2018-05-02T22:56:45.184325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Iteration 1 ##\n",
      "There are one-scale raters!\n",
      "one_Scale_rater_eliminator excuted\n",
      "\n",
      "\n",
      "There are some user or item (if not None) has less than 10 ratings!\n",
      "core_operator excuted!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "## Iteration 2 ##\n",
      "There are one-scale raters!\n",
      "one_Scale_rater_eliminator excuted\n",
      "\n",
      "\n",
      "There are some user or item (if not None) has less than 10 ratings!\n",
      "core_operator excuted!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "## Iteration 3 ##\n",
      "No one scale Rater!\n",
      "\n",
      "\n",
      "There are some user or item (if not None) has less than 10 ratings!\n",
      "core_operator excuted!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "## Iteration 4 ##\n",
      "No one scale Rater!\n",
      "\n",
      "\n",
      "No item & user has less than 10 ratinngs!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Data is cleaned!\n"
     ]
    }
   ],
   "source": [
    "#limit user data to tv & comedy based only\n",
    "movie_comedy_anime= Anime_subset(Anime,Anime_rating,'Movie','Comedy')\n",
    "\n",
    "\n",
    "#perform eliminaton & core_operation\n",
    "movie_comedy_anime_core=data_cleaner(movie_comedy_anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T22:58:06.144861Z",
     "start_time": "2018-05-02T22:58:06.131686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184949 entries, 162 to 7813429\n",
      "Data columns (total 3 columns):\n",
      "user_id     184949 non-null int64\n",
      "anime_id    184949 non-null int64\n",
      "rating      184949 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "## size &info\n",
    "movie_comedy_anime_core.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print summary of  Movie & comedy based Anime Rating Data after cleaning ## \\n')\n",
    "print('Number of observations: {} '.format(len(movie_comedy_anime_core)))\n",
    "\n",
    "\n",
    "for i in movie_comedy_anime_core.nunique().index:\n",
    "    print('Number of Unique {0}s: {1}'.format(i.split('_')[0],movie_comedy_anime_core.nunique()[i]))\n",
    "\n",
    "print('*rating scales: {}'.format(np.sort(movie_comedy_anime_core['rating'].unique())))\n",
    "\n",
    "print('Density: {}'.format(len(movie_comedy_anime_core)/(movie_comedy_anime_core.nunique()[0]*movie_comedy_anime_core.nunique()[1])))\n",
    "\n",
    "print('='*80)    \n",
    "print('\\n\\n## first 10 rows of  TV & comedy based Anime Rating Data after cleaning ## \\n')\n",
    "print(movie_comedy_anime_core.head())\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T23:00:40.071152Z",
     "start_time": "2018-05-02T23:00:39.071821Z"
    }
   },
   "outputs": [],
   "source": [
    "#write to csv\n",
    "movie_comedy_anime_core.to_csv('core_movie_comedy_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Form of Anime Rating Datasets ready in Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting (train ,test) using Straitification on `'user_id'`\n",
    "using straitification on user to make sure each user apear in both train and test set as stated proportion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T20:33:59.878901Z",
     "start_time": "2018-05-16T20:33:58.268443Z"
    }
   },
   "outputs": [],
   "source": [
    "#load final form of anime rating data 'core_movie_comedy_rating.csv'\n",
    "final_form_data=pd.read_csv('core_movie_comedy_rating.csv')\n",
    "\n",
    "#splittig on final form of data\n",
    "train, test = train_test_split(final_form_data, test_size=0.2, random_state=1, \n",
    "                               stratify=final_form_data['user_id'])\n",
    "\n",
    "##write train & test to csv\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Final form of Anime rating  Data ( final_form_data, train, test ) into Surprise Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T22:51:26.118184Z",
     "start_time": "2018-05-18T22:51:24.919095Z"
    }
   },
   "outputs": [],
   "source": [
    "## load data into suprise object ##\n",
    "reader = Reader(line_format='user item rating', sep=',',rating_scale=(1, 10),skip_lines=1)\n",
    "WholeSet = Dataset.load_from_file('core_movie_comedy_rating.csv', reader)\n",
    "S_train = Dataset.load_from_file('train.csv', reader)\n",
    "S_test = Dataset.load_from_file('test.csv', reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Convert data into surprise training sets & testing sets for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T22:51:29.086193Z",
     "start_time": "2018-05-18T22:51:28.418664Z"
    }
   },
   "outputs": [],
   "source": [
    "# surprise trainset  \n",
    "trainset = S_train.build_full_trainset() # 80% of data for training\n",
    "WholeSet_train = WholeSet.build_full_trainset() # wholeSet as training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T22:51:30.667270Z",
     "start_time": "2018-05-18T22:51:30.629775Z"
    }
   },
   "outputs": [],
   "source": [
    "# testset for evaluating RMSE\n",
    "\n",
    "testset = list(map(lambda x : x[0:3],S_test.raw_ratings)) # 20% of data as testset for evaluating rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T22:51:40.178769Z",
     "start_time": "2018-05-18T22:51:32.676961Z"
    }
   },
   "outputs": [],
   "source": [
    "# testset for evaluating relevence(Precision, Recall, NDCG)\n",
    "NoRatingSet = WholeSet_train.build_anti_testset(fill=1) #whole unknown rating\n",
    "\n",
    "_, noRate_test = train_test_split(NoRatingSet, test_size=0.2, random_state=1, stratify=list(map(lambda x: x[0], NoRatingSet)))\n",
    "\n",
    "testPlusUnknown=testset+noRate_test #testset + 20% of unknown rating for evaluating relevence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T06:05:20.458449Z",
     "start_time": "2018-05-19T06:05:20.409651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col1 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col5 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col6 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col7 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96ba\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Number of Rating</th> \n",
       "        <th class=\"col_heading level0 col1\" >Number of user</th> \n",
       "        <th class=\"col_heading level0 col2\" >Number of Item</th> \n",
       "        <th class=\"col_heading level0 col3\" >Missing value (Rating = -1)</th> \n",
       "        <th class=\"col_heading level0 col4\" >Number of Item less than 10 rating</th> \n",
       "        <th class=\"col_heading level0 col5\" >Number of User less than 10 rating</th> \n",
       "        <th class=\"col_heading level0 col6\" >Number of user that only rate with one value</th> \n",
       "        <th class=\"col_heading level0 col7\" >Density</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96balevel0_row0\" class=\"row_heading level0 row0\" >Original Anime Rating data</th> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col0\" class=\"data row0 col0\" >7813737</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col1\" class=\"data row0 col1\" >73515</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col2\" class=\"data row0 col2\" >11200</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col3\" class=\"data row0 col3\" >1476496</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col4\" class=\"data row0 col4\" >2562</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col5\" class=\"data row0 col5\" >14482</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col6\" class=\"data row0 col6\" >5476</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow0_col7\" class=\"data row0 col7\" >0.0092</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96balevel0_row1\" class=\"row_heading level0 row1\" >Final Form of Anime Rating data</th> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col0\" class=\"data row1 col0\" >184949</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col1\" class=\"data row1 col1\" >8905</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col2\" class=\"data row1 col2\" >334</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col3\" class=\"data row1 col3\" >0</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col4\" class=\"data row1 col4\" >0</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col5\" class=\"data row1 col5\" >0</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col6\" class=\"data row1 col6\" >0</td> \n",
       "        <td id=\"T_9c570986_5b2a_11e8_83fe_b8e8560a96barow1_col7\" class=\"data row1 col7\" >0.0622</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a27928470>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read report \n",
    "data_ccompare=pd.read_csv('data_ccompare.csv',index_col=0)\n",
    "data_ccompare.style.highlight_min(data_ccompare.columns[:-1]).highlight_max(['Density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Comment:__\n",
    "\n",
    "After filtering out all the perfect & the worst rating user/item, and applying 10 core operation on the anime rating table,  the __density__ of  final form of anime rating data increase from __~0.009 to ~ 0.016__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T06:01:07.110529Z",
     "start_time": "2018-05-19T06:01:07.099324Z"
    }
   },
   "outputs": [],
   "source": [
    "#save reprot as csv\n",
    "data_ccompare.to_csv('data_ccompare.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T23:12:45.326170Z",
     "start_time": "2018-05-18T23:12:42.497441Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Final form of Anime (Comedy & movie based) rating data ##\n",
      "\n",
      "Number of Observation: 184949\n",
      "Number of Users: 8905\n",
      "Number of items: 334\n",
      "Density: 0.06218298943942547\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "## Surprise trainset  object (80% of whole data) ##\n",
      "\n",
      "Object Type: <class 'surprise.trainset.Trainset'>\n",
      "Number of observations: 147959\n",
      "Number of Users ( trainset.n_users ): 8905\n",
      "Number of items ( trainset.n_items ): 334\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "## Holdeout Testset (20% of whole data) for evalauting Rating Prediction performance##\n",
      "\n",
      "Object Type: <class 'list'>\n",
      "Number of Observation: 36990\n",
      "Number of Users: 8905\n",
      "Number of items: 329\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "## Testset (Holdeout testset + 20% unknown rating data) for evalauting Reccomendation performance ##\n",
      "\n",
      "Object Type: <class 'list'>\n",
      "Number of Observation: 594855\n",
      "Number of Users: 8905\n",
      "Number of items: 334\n",
      "==============================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#summary of data that will be used in surprise\n",
    "\n",
    "print('## Final form of Anime (Comedy & movie based) rating data ##\\n')\n",
    "print('Number of Observation: {}'.format(len(WholeSet.raw_ratings)))\n",
    "print('Number of Users: {}'.format(WholeSet_train.n_users))\n",
    "print('Number of items: {}'.format(WholeSet_train.n_items))\n",
    "print('Density: {}'.format(WholeSet_train.n_ratings/(WholeSet_train.n_users*WholeSet_train.n_items)))\n",
    "print('='*110)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "print('## Surprise trainset  object (80% of whole data) ##\\n')\n",
    "print('Object Type: {}'.format(type(trainset)))\n",
    "print('Number of observations: {}'.format(len(S_train.raw_ratings)))\n",
    "print('Number of Users ( trainset.n_users ): {}'.format(trainset.n_users))\n",
    "print('Number of items ( trainset.n_items ): {}'.format(trainset.n_items))\n",
    "print('='*110)\n",
    "print('\\n')\n",
    "\n",
    "print('## Holdeout Testset (20% of whole data) for evalauting Rating Prediction performance##\\n')\n",
    "\n",
    "print('Object Type: {}'.format(type(testset)))\n",
    "print('Number of Observation: {}'.format(len(S_test.raw_ratings)))\n",
    "print('Number of Users: {}'.format(len(np.unique(np.array(testset)[:,0],return_counts=True)[1])))\n",
    "print('Number of items: {}'.format(len(np.unique(np.array(testset)[:,1],return_counts=True)[1])))\n",
    "print('='*110)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('## Testset (Holdeout testset + 20% unknown rating data) for evalauting Reccomendation performance ##\\n')\n",
    "print('Object Type: {}'.format(type(testPlusUnknown)))\n",
    "print('Number of Observation: {}'.format(len(testPlusUnknown)))\n",
    "print('Number of Users: {}'.format(len(np.unique(np.array(testPlusUnknown)[:,0],return_counts=True)[1])))\n",
    "print('Number of items: {}'.format(len(np.unique(np.array(testPlusUnknown)[:,1],return_counts=True)[1])))\n",
    "print('='*110)\n",
    "print('\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "234px",
    "width": "618px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "807px",
    "left": "461.98529052734375px",
    "top": "174.46690368652344px",
    "width": "481px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 362.64705896377563,
   "position": {
    "height": "385px",
    "left": "1310px",
    "right": "33.125px",
    "top": "153.91543579101563px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
